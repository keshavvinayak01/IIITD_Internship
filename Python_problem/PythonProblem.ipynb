{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part of the program where the data will be extracted and will be saved in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading twitter API credentials from the file which was saved\n",
    "with open('twitter_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "    consumer_key = info['CONSUMER_KEY']\n",
    "    consumer_secret = info['CONSUMER_SECRET']\n",
    "    access_key = info['ACCESS_KEY']\n",
    "    access_secret = info['ACCESS_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of a list to hold all Tweets\n",
    "alltweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorization and initialization\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will get the tweets with multiple requests of 200 tweets each\n",
    "new_tweets = api.user_timeline(screen_name=\"midasIIITD\", count=200)\n",
    "# Appending the json part of the data to list\n",
    "for tweet in new_tweets:\n",
    "    alltweets.append(tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save id of 1 less than the oldest tweet\n",
    "oldest = alltweets[-1][\"id\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...331 tweets downloaded so far\n",
      "...331 tweets downloaded so far\n",
      "Total tweets downloaded 331\n"
     ]
    }
   ],
   "source": [
    "# grabbing tweets till none are left\n",
    "while len(new_tweets) > 0:  \n",
    "    # all subsiquent requests use the max_id param to prevent duplicates\n",
    "    new_tweets = api.user_timeline(screen_name = \"midasIIITD\",count=200, max_id=oldest)\n",
    "\n",
    "    # save most recent tweets\n",
    "    # Appending the json part of the data to list\n",
    "    for tweet in new_tweets:\n",
    "        alltweets.append(tweet._json)\n",
    "    oldest = alltweets[-1][\"id\"] - 1\n",
    "\n",
    "    print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "print(\"Total tweets downloaded %s\" % (len(alltweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new JSON file and dumping the value into it\n",
    "file = open('tweet.json', 'w')\n",
    "json.dump(alltweets, file,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.jsonl', 'w') as outfile:\n",
    "    for entry in alltweets:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second part of the program to parse the json file and display the output in tabular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'media': [{'display_url': 'pic.twitter.com/ccX4Uhxjn8',\n",
       "   'expanded_url': 'https://twitter.com/kdnuggets/status/1114014848369799169/photo/1',\n",
       "   'id': 1114014846817796099,\n",
       "   'id_str': '1114014846817796099',\n",
       "   'indices': [75, 98],\n",
       "   'media_url': 'http://pbs.twimg.com/media/D3XGmdMWAAM7bXv.png',\n",
       "   'media_url_https': 'https://pbs.twimg.com/media/D3XGmdMWAAM7bXv.png',\n",
       "   'sizes': {'large': {'h': 300, 'resize': 'fit', 'w': 640},\n",
       "    'medium': {'h': 300, 'resize': 'fit', 'w': 640},\n",
       "    'small': {'h': 300, 'resize': 'fit', 'w': 640},\n",
       "    'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "   'source_status_id': 1114014848369799169,\n",
       "   'source_status_id_str': '1114014848369799169',\n",
       "   'source_user_id': 20167623,\n",
       "   'source_user_id_str': '20167623',\n",
       "   'type': 'photo',\n",
       "   'url': 'https://t.co/ccX4Uhxjn8'}]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltweets[6]['extended_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = []\n",
    "images = []\n",
    "text = []\n",
    "created_at = []\n",
    "favorite = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(alltweets)):\n",
    "    rt.append(alltweets[i]['retweet_count'])\n",
    "    text.append(alltweets[i]['text'])\n",
    "    created_at.append(alltweets[i]['created_at'])\n",
    "    favorite.append(alltweets[i]['favorite_count'])\n",
    "    try:\n",
    "        images.append(len(alltweets[i]['extended_entities']['media']))\n",
    "    except:\n",
    "        images.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Wed Apr 03 17:04:32 +0000 2019',\n",
       " 'entities': {'hashtags': [],\n",
       "  'symbols': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'id': 4783690002,\n",
       "    'id_str': '4783690002',\n",
       "    'indices': [3, 14],\n",
       "    'name': 'DeepMind',\n",
       "    'screen_name': 'DeepMindAI'}]},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 1113487457780215808,\n",
       " 'id_str': '1113487457780215808',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'place': None,\n",
       " 'retweet_count': 849,\n",
       " 'retweeted': False,\n",
       " 'retweeted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Wed Apr 03 12:38:17 +0000 2019',\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'urls': [{'display_url': 'twitter.com/i/web/status/1…',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1113420454860083201',\n",
       "     'indices': [116, 139],\n",
       "     'url': 'https://t.co/SZRSMvEeO3'}],\n",
       "   'user_mentions': []},\n",
       "  'favorite_count': 2358,\n",
       "  'favorited': False,\n",
       "  'geo': None,\n",
       "  'id': 1113420454860083201,\n",
       "  'id_str': '1113420454860083201',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'en',\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 849,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       "  'text': \"Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the… https://t.co/SZRSMvEeO3\",\n",
       "  'truncated': True,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Tue Jan 19 13:46:08 +0000 2016',\n",
       "   'default_profile': True,\n",
       "   'default_profile_image': False,\n",
       "   'description': 'Founded in 2010.  Building Artificial General Intelligence. The creators of #AlphaGo and Atari DQN',\n",
       "   'entities': {'description': {'urls': []},\n",
       "    'url': {'urls': [{'display_url': 'deepmind.com',\n",
       "       'expanded_url': 'http://www.deepmind.com',\n",
       "       'indices': [0, 23],\n",
       "       'url': 'https://t.co/8B3TFFIGoP'}]}},\n",
       "   'favourites_count': 224,\n",
       "   'follow_request_sent': False,\n",
       "   'followers_count': 225068,\n",
       "   'following': True,\n",
       "   'friends_count': 110,\n",
       "   'geo_enabled': False,\n",
       "   'has_extended_profile': False,\n",
       "   'id': 4783690002,\n",
       "   'id_str': '4783690002',\n",
       "   'is_translation_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'lang': 'en',\n",
       "   'listed_count': 3244,\n",
       "   'location': 'London, UK',\n",
       "   'name': 'DeepMind',\n",
       "   'notifications': False,\n",
       "   'profile_background_color': 'F5F8FA',\n",
       "   'profile_background_image_url': None,\n",
       "   'profile_background_image_url_https': None,\n",
       "   'profile_background_tile': False,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/4783690002/1484305927',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/692405474986164224/NzcXa05I_normal.png',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/692405474986164224/NzcXa05I_normal.png',\n",
       "   'profile_link_color': '1DA1F2',\n",
       "   'profile_sidebar_border_color': 'C0DEED',\n",
       "   'profile_sidebar_fill_color': 'DDEEF6',\n",
       "   'profile_text_color': '333333',\n",
       "   'profile_use_background_image': True,\n",
       "   'protected': False,\n",
       "   'screen_name': 'DeepMindAI',\n",
       "   'statuses_count': 822,\n",
       "   'time_zone': None,\n",
       "   'translator_type': 'none',\n",
       "   'url': 'https://t.co/8B3TFFIGoP',\n",
       "   'utc_offset': None,\n",
       "   'verified': False}},\n",
       " 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       " 'text': \"RT @DeepMindAI: Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilitie…\",\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Mon Jul 23 11:26:04 +0000 2018',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'description': 'MIDAS is a group of researchers at IIIT-Delhi who study, analyze, and build different multimedia systems for society leveraging multimodal information.',\n",
       "  'entities': {'description': {'urls': []},\n",
       "   'url': {'urls': [{'display_url': 'midas.iiitd.edu.in',\n",
       "      'expanded_url': 'http://midas.iiitd.edu.in/',\n",
       "      'indices': [0, 23],\n",
       "      'url': 'https://t.co/Uwg7oSM6mE'}]}},\n",
       "  'favourites_count': 142,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 255,\n",
       "  'following': True,\n",
       "  'friends_count': 42,\n",
       "  'geo_enabled': False,\n",
       "  'has_extended_profile': False,\n",
       "  'id': 1021355762575073281,\n",
       "  'id_str': '1021355762575073281',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 0,\n",
       "  'location': 'New Delhi, India',\n",
       "  'name': 'MIDAS IIITD',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': None,\n",
       "  'profile_background_image_url_https': None,\n",
       "  'profile_background_tile': False,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1021355762575073281/1554320878',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1021356444921212928/WmSTJCUs_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1021356444921212928/WmSTJCUs_normal.jpg',\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'midasIIITD',\n",
       "  'statuses_count': 331,\n",
       "  'time_zone': None,\n",
       "  'translator_type': 'none',\n",
       "  'url': 'https://t.co/Uwg7oSM6mE',\n",
       "  'utc_offset': None,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alltweets[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Things i noted while scraping,the twitter api does NOT return all images from retweeted posts, so I tried scraping \n",
    "#using bs4 all the urls of retweeted posts, but as it turns out, scraping that many urls are not allowed by twitter,\n",
    "#Also i printed alltweets[8], a retweet that contains an image, however no such response was given by the twitter api\n",
    "#So, in the final dataframe, the image count of all rows are not correct, however the rest of the information is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe['Date and time'] = created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe['number of favorites/likes'] = favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe['retweets count'] = rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe['images'] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Date and time</th>\n",
       "      <th>number of favorites/likes</th>\n",
       "      <th>retweets count</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other queries: \"If using Twitter api, it does ...</td>\n",
       "      <td>Sun Apr 07 05:32:27 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Response to some queries asked by students on ...</td>\n",
       "      <td>Sun Apr 07 05:29:40 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @kdnuggets: Top 8 #Free Must-Read #Books on...</td>\n",
       "      <td>Sat Apr 06 17:11:29 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nupur_baghel @PennDATS Congratulation @nupur_...</td>\n",
       "      <td>Sat Apr 06 16:43:27 +0000 2019</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have emailed the task details to all candid...</td>\n",
       "      <td>Fri Apr 05 16:08:37 +0000 2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @rfpvjr: Our NAACL paper on polarization in...</td>\n",
       "      <td>Fri Apr 05 04:05:11 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @kdnuggets: Effective Transfer Learning For...</td>\n",
       "      <td>Fri Apr 05 04:04:43 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @stanfordnlp: What’s new in @Stanford CS224...</td>\n",
       "      <td>Wed Apr 03 18:31:53 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @DeepMindAI: Today we're releasing a large-...</td>\n",
       "      <td>Wed Apr 03 17:04:32 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @ylecun: Congratulations Jitendra Malik !\\n...</td>\n",
       "      <td>Wed Apr 03 09:03:40 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @IIITDelhi: Another chance to take admissio...</td>\n",
       "      <td>Wed Apr 03 07:46:02 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dear @midasIIITD internship candidates who hav...</td>\n",
       "      <td>Tue Apr 02 04:20:13 +0000 2019</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Looking forward to your paper submission to @I...</td>\n",
       "      <td>Tue Apr 02 02:44:54 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @ngrams: Reproducibility in multimedia rese...</td>\n",
       "      <td>Tue Apr 02 02:35:44 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Online application for https://t.co/DJFDrQsHZP...</td>\n",
       "      <td>Mon Apr 01 06:53:08 +0000 2019</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @ACMMM19: A final reminder of the Reproduci...</td>\n",
       "      <td>Sun Mar 31 10:21:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @isarth23: Thanks for the support and help ...</td>\n",
       "      <td>Fri Mar 29 19:43:24 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Since SemEval-2019 will be held June 6-7, 2019...</td>\n",
       "      <td>Fri Mar 29 17:16:40 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>+@aggarwal_kartik.\\nCongrats! Wish you many mo...</td>\n",
       "      <td>Fri Mar 29 17:04:30 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @aggarwal_kartik: Our work (@midasIIITD ) a...</td>\n",
       "      <td>Fri Mar 29 17:03:29 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Congratulations! @midasIIITD team, @isarth23 @...</td>\n",
       "      <td>Fri Mar 29 17:02:24 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@EEMLcommunity @radamihalcea too many deadline...</td>\n",
       "      <td>Fri Mar 29 05:35:22 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @stanfordnlp: CS224N Natural Language Proce...</td>\n",
       "      <td>Thu Mar 28 16:55:01 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT @ylecun: Learn PyTorch by running on Google...</td>\n",
       "      <td>Thu Mar 28 16:54:37 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dr. Vineeth N Balasubramanian will present a T...</td>\n",
       "      <td>Wed Mar 27 16:09:09 +0000 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @ylecun: I am extremely honored to be the r...</td>\n",
       "      <td>Wed Mar 27 11:53:40 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Thanks to all shortlisted candidates for submi...</td>\n",
       "      <td>Tue Mar 26 18:12:27 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@IEEEBigMM19 @ACMMM19 and 6 days left for work...</td>\n",
       "      <td>Tue Mar 26 05:54:49 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT @IEEEBigMM19: Hurry Up!\\n6 Days left for Ab...</td>\n",
       "      <td>Tue Mar 26 05:50:10 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Congratulations @midasIIITD students Simra Sha...</td>\n",
       "      <td>Mon Mar 25 13:01:57 +0000 2019</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>RT @TensorFlow: TensorFlow 1.10.0 has been rel...</td>\n",
       "      <td>Thu Aug 09 05:59:57 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>@midasIIITD is looking for motivated IIITD MTe...</td>\n",
       "      <td>Wed Aug 08 11:30:56 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>@IIITDelhi @ponguru @RatnRajiv The results of ...</td>\n",
       "      <td>Wed Aug 08 05:53:48 +0000 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>RT @IIITDelhi: @midasIIITD has secured rank 1 ...</td>\n",
       "      <td>Wed Aug 08 05:45:58 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>RT @kdnuggets: Comparison of Top 6 Python NLP ...</td>\n",
       "      <td>Tue Aug 07 07:16:33 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Check more details of the 20th IEEE Internatio...</td>\n",
       "      <td>Tue Aug 07 02:05:12 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>MR2AMC@ISM 2018 will be organized by @RatnRaji...</td>\n",
       "      <td>Tue Aug 07 01:58:49 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Our workshop proposal named, \"MR2AMC: Multimod...</td>\n",
       "      <td>Tue Aug 07 01:50:33 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>@NUSComputing Congratulations Abdelhak and Pro...</td>\n",
       "      <td>Mon Aug 06 17:48:23 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>RT @goodfellow_ian: One of the most anticipate...</td>\n",
       "      <td>Mon Aug 06 17:46:59 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>@the_dhumketu Great to have you in @midasIIITD</td>\n",
       "      <td>Mon Aug 06 06:06:47 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Congratulation @soujanyaporia for being appoin...</td>\n",
       "      <td>Fri Aug 03 05:56:33 +0000 2018</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>@IIITDelhi @the_dhumketu Thanks team @midasIII...</td>\n",
       "      <td>Wed Aug 01 11:47:15 +0000 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>RT @IIITDelhi: Congratulations @midasIIITD int...</td>\n",
       "      <td>Wed Aug 01 11:20:07 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>RT @learning_pt: Profile of the 5 Indian under...</td>\n",
       "      <td>Wed Aug 01 05:06:47 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Have a look at the list of accepted papers in ...</td>\n",
       "      <td>Tue Jul 31 12:11:52 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...</td>\n",
       "      <td>Tue Jul 31 02:06:26 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...</td>\n",
       "      <td>Mon Jul 30 07:30:51 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>RT @ylecun: Jitendra Malik, who directs FAIR-M...</td>\n",
       "      <td>Sat Jul 28 11:07:11 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>RT @kdnuggets: .@Bloomberg launches free cours...</td>\n",
       "      <td>Sat Jul 28 06:14:09 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>RT @TechAtBloomberg: Missed #PyLondinium18? Wa...</td>\n",
       "      <td>Sat Jul 28 06:13:48 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>RT @IIITDelhi: We are delighted to announce th...</td>\n",
       "      <td>Sat Jul 28 04:08:21 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Get ready for the annual technical fest of @II...</td>\n",
       "      <td>Fri Jul 27 06:46:44 +0000 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Congratulations Dr. @RatnRajiv and team @midas...</td>\n",
       "      <td>Fri Jul 27 04:07:31 +0000 2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Congratulations MIDAS @midasIIITD intern Prakh...</td>\n",
       "      <td>Wed Jul 25 05:14:35 +0000 2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm</td>\n",
       "      <td>Tue Jul 24 10:33:23 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>It feels great to be the part of @IIITDelhi. h...</td>\n",
       "      <td>Tue Jul 24 10:12:34 +0000 2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Thank you, @toonzratn for designing the logo o...</td>\n",
       "      <td>Tue Jul 24 09:46:26 +0000 2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>We are on Facebook too. Like our page to get o...</td>\n",
       "      <td>Mon Jul 23 16:25:05 +0000 2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>MIDAS is a group of researchers at IIIT-Delhi ...</td>\n",
       "      <td>Mon Jul 23 12:53:15 +0000 2018</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Other queries: \"If using Twitter api, it does ...   \n",
       "1    Response to some queries asked by students on ...   \n",
       "2    RT @kdnuggets: Top 8 #Free Must-Read #Books on...   \n",
       "3    @nupur_baghel @PennDATS Congratulation @nupur_...   \n",
       "4    We have emailed the task details to all candid...   \n",
       "5    RT @rfpvjr: Our NAACL paper on polarization in...   \n",
       "6    RT @kdnuggets: Effective Transfer Learning For...   \n",
       "7    RT @stanfordnlp: What’s new in @Stanford CS224...   \n",
       "8    RT @DeepMindAI: Today we're releasing a large-...   \n",
       "9    RT @ylecun: Congratulations Jitendra Malik !\\n...   \n",
       "10   RT @IIITDelhi: Another chance to take admissio...   \n",
       "11   Dear @midasIIITD internship candidates who hav...   \n",
       "12   Looking forward to your paper submission to @I...   \n",
       "13   RT @ngrams: Reproducibility in multimedia rese...   \n",
       "14   Online application for https://t.co/DJFDrQsHZP...   \n",
       "15   RT @ACMMM19: A final reminder of the Reproduci...   \n",
       "16   RT @isarth23: Thanks for the support and help ...   \n",
       "17   Since SemEval-2019 will be held June 6-7, 2019...   \n",
       "18   +@aggarwal_kartik.\\nCongrats! Wish you many mo...   \n",
       "19   RT @aggarwal_kartik: Our work (@midasIIITD ) a...   \n",
       "20   Congratulations! @midasIIITD team, @isarth23 @...   \n",
       "21   @EEMLcommunity @radamihalcea too many deadline...   \n",
       "22   RT @stanfordnlp: CS224N Natural Language Proce...   \n",
       "23   RT @ylecun: Learn PyTorch by running on Google...   \n",
       "24   Dr. Vineeth N Balasubramanian will present a T...   \n",
       "25   RT @ylecun: I am extremely honored to be the r...   \n",
       "26   Thanks to all shortlisted candidates for submi...   \n",
       "27   @IEEEBigMM19 @ACMMM19 and 6 days left for work...   \n",
       "28   RT @IEEEBigMM19: Hurry Up!\\n6 Days left for Ab...   \n",
       "29   Congratulations @midasIIITD students Simra Sha...   \n",
       "..                                                 ...   \n",
       "301  RT @TensorFlow: TensorFlow 1.10.0 has been rel...   \n",
       "302  @midasIIITD is looking for motivated IIITD MTe...   \n",
       "303  @IIITDelhi @ponguru @RatnRajiv The results of ...   \n",
       "304  RT @IIITDelhi: @midasIIITD has secured rank 1 ...   \n",
       "305  RT @kdnuggets: Comparison of Top 6 Python NLP ...   \n",
       "306  Check more details of the 20th IEEE Internatio...   \n",
       "307  MR2AMC@ISM 2018 will be organized by @RatnRaji...   \n",
       "308  Our workshop proposal named, \"MR2AMC: Multimod...   \n",
       "309  @NUSComputing Congratulations Abdelhak and Pro...   \n",
       "310  RT @goodfellow_ian: One of the most anticipate...   \n",
       "311     @the_dhumketu Great to have you in @midasIIITD   \n",
       "312  Congratulation @soujanyaporia for being appoin...   \n",
       "313  @IIITDelhi @the_dhumketu Thanks team @midasIII...   \n",
       "314  RT @IIITDelhi: Congratulations @midasIIITD int...   \n",
       "315  RT @learning_pt: Profile of the 5 Indian under...   \n",
       "316  Have a look at the list of accepted papers in ...   \n",
       "317  RT @goodfellow_ian: https://t.co/hYiWI7ntyk Te...   \n",
       "318  RT @IIITDelhi: Congratulations Dr. @RatnRajiv ...   \n",
       "319  RT @ylecun: Jitendra Malik, who directs FAIR-M...   \n",
       "320  RT @kdnuggets: .@Bloomberg launches free cours...   \n",
       "321  RT @TechAtBloomberg: Missed #PyLondinium18? Wa...   \n",
       "322  RT @IIITDelhi: We are delighted to announce th...   \n",
       "323  Get ready for the annual technical fest of @II...   \n",
       "324  Congratulations Dr. @RatnRajiv and team @midas...   \n",
       "325  Congratulations MIDAS @midasIIITD intern Prakh...   \n",
       "326    MIDAS@IIITD foundation. https://t.co/LKuzyBHzjm   \n",
       "327  It feels great to be the part of @IIITDelhi. h...   \n",
       "328  Thank you, @toonzratn for designing the logo o...   \n",
       "329  We are on Facebook too. Like our page to get o...   \n",
       "330  MIDAS is a group of researchers at IIIT-Delhi ...   \n",
       "\n",
       "                      Date and time  number of favorites/likes  \\\n",
       "0    Sun Apr 07 05:32:27 +0000 2019                          1   \n",
       "1    Sun Apr 07 05:29:40 +0000 2019                          2   \n",
       "2    Sat Apr 06 17:11:29 +0000 2019                          0   \n",
       "3    Sat Apr 06 16:43:27 +0000 2019                         14   \n",
       "4    Fri Apr 05 16:08:37 +0000 2019                         10   \n",
       "5    Fri Apr 05 04:05:11 +0000 2019                          0   \n",
       "6    Fri Apr 05 04:04:43 +0000 2019                          0   \n",
       "7    Wed Apr 03 18:31:53 +0000 2019                          0   \n",
       "8    Wed Apr 03 17:04:32 +0000 2019                          0   \n",
       "9    Wed Apr 03 09:03:40 +0000 2019                          0   \n",
       "10   Wed Apr 03 07:46:02 +0000 2019                          0   \n",
       "11   Tue Apr 02 04:20:13 +0000 2019                          8   \n",
       "12   Tue Apr 02 02:44:54 +0000 2019                          5   \n",
       "13   Tue Apr 02 02:35:44 +0000 2019                          0   \n",
       "14   Mon Apr 01 06:53:08 +0000 2019                          7   \n",
       "15   Sun Mar 31 10:21:24 +0000 2019                          0   \n",
       "16   Fri Mar 29 19:43:24 +0000 2019                          0   \n",
       "17   Fri Mar 29 17:16:40 +0000 2019                          9   \n",
       "18   Fri Mar 29 17:04:30 +0000 2019                          2   \n",
       "19   Fri Mar 29 17:03:29 +0000 2019                          0   \n",
       "20   Fri Mar 29 17:02:24 +0000 2019                          9   \n",
       "21   Fri Mar 29 05:35:22 +0000 2019                          0   \n",
       "22   Thu Mar 28 16:55:01 +0000 2019                          0   \n",
       "23   Thu Mar 28 16:54:37 +0000 2019                          0   \n",
       "24   Wed Mar 27 16:09:09 +0000 2019                          4   \n",
       "25   Wed Mar 27 11:53:40 +0000 2019                          0   \n",
       "26   Tue Mar 26 18:12:27 +0000 2019                          5   \n",
       "27   Tue Mar 26 05:54:49 +0000 2019                          2   \n",
       "28   Tue Mar 26 05:50:10 +0000 2019                          0   \n",
       "29   Mon Mar 25 13:01:57 +0000 2019                         18   \n",
       "..                              ...                        ...   \n",
       "301  Thu Aug 09 05:59:57 +0000 2018                          0   \n",
       "302  Wed Aug 08 11:30:56 +0000 2018                          2   \n",
       "303  Wed Aug 08 05:53:48 +0000 2018                          3   \n",
       "304  Wed Aug 08 05:45:58 +0000 2018                          0   \n",
       "305  Tue Aug 07 07:16:33 +0000 2018                          0   \n",
       "306  Tue Aug 07 02:05:12 +0000 2018                          1   \n",
       "307  Tue Aug 07 01:58:49 +0000 2018                          1   \n",
       "308  Tue Aug 07 01:50:33 +0000 2018                          1   \n",
       "309  Mon Aug 06 17:48:23 +0000 2018                          0   \n",
       "310  Mon Aug 06 17:46:59 +0000 2018                          0   \n",
       "311  Mon Aug 06 06:06:47 +0000 2018                          0   \n",
       "312  Fri Aug 03 05:56:33 +0000 2018                          6   \n",
       "313  Wed Aug 01 11:47:15 +0000 2018                          5   \n",
       "314  Wed Aug 01 11:20:07 +0000 2018                          0   \n",
       "315  Wed Aug 01 05:06:47 +0000 2018                          0   \n",
       "316  Tue Jul 31 12:11:52 +0000 2018                          1   \n",
       "317  Tue Jul 31 02:06:26 +0000 2018                          0   \n",
       "318  Mon Jul 30 07:30:51 +0000 2018                          0   \n",
       "319  Sat Jul 28 11:07:11 +0000 2018                          0   \n",
       "320  Sat Jul 28 06:14:09 +0000 2018                          0   \n",
       "321  Sat Jul 28 06:13:48 +0000 2018                          0   \n",
       "322  Sat Jul 28 04:08:21 +0000 2018                          0   \n",
       "323  Fri Jul 27 06:46:44 +0000 2018                          3   \n",
       "324  Fri Jul 27 04:07:31 +0000 2018                          8   \n",
       "325  Wed Jul 25 05:14:35 +0000 2018                          5   \n",
       "326  Tue Jul 24 10:33:23 +0000 2018                          2   \n",
       "327  Tue Jul 24 10:12:34 +0000 2018                          2   \n",
       "328  Tue Jul 24 09:46:26 +0000 2018                          4   \n",
       "329  Mon Jul 23 16:25:05 +0000 2018                          3   \n",
       "330  Mon Jul 23 12:53:15 +0000 2018                          7   \n",
       "\n",
       "     retweets count  images  \n",
       "0                 0       0  \n",
       "1                 0       0  \n",
       "2                 2       0  \n",
       "3                 3       0  \n",
       "4                 1       0  \n",
       "5                16       0  \n",
       "6                10       1  \n",
       "7                58       0  \n",
       "8               849       0  \n",
       "9                16       0  \n",
       "10                4       0  \n",
       "11                1       0  \n",
       "12                1       0  \n",
       "13                7       0  \n",
       "14                2       0  \n",
       "15               10       0  \n",
       "16                2       0  \n",
       "17                1       0  \n",
       "18                0       0  \n",
       "19                1       0  \n",
       "20                1       0  \n",
       "21                0       0  \n",
       "22              714       0  \n",
       "23              157       0  \n",
       "24                1       0  \n",
       "25             1545       0  \n",
       "26                1       0  \n",
       "27                0       0  \n",
       "28                3       0  \n",
       "29                1       0  \n",
       "..              ...     ...  \n",
       "301             265       0  \n",
       "302               1       0  \n",
       "303               1       1  \n",
       "304               1       0  \n",
       "305              40       1  \n",
       "306               1       0  \n",
       "307               1       0  \n",
       "308               1       0  \n",
       "309               0       0  \n",
       "310             103       1  \n",
       "311               0       0  \n",
       "312               1       0  \n",
       "313               1       1  \n",
       "314               4       0  \n",
       "315               4       0  \n",
       "316               0       0  \n",
       "317             264       0  \n",
       "318               2       0  \n",
       "319              57       0  \n",
       "320             105       0  \n",
       "321               7       0  \n",
       "322               6       0  \n",
       "323               2       0  \n",
       "324               2       0  \n",
       "325               1       0  \n",
       "326               1       0  \n",
       "327               1       0  \n",
       "328               1       1  \n",
       "329               1       0  \n",
       "330               4       0  \n",
       "\n",
       "[331 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
